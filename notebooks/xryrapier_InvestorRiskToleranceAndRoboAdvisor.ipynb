{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83708667-4fdc-1563-7b3a-06b6575d2865"
   },
   "source": [
    "\n",
    "\n",
    "# Investor Risk Tolerance and Robo advisors\n",
    "\n",
    "The goal of this case study is to build a machine learning model to predict the risk tolerance or risk aversion of an investor, and use the model in a robo-advisor dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Libraries and Dataset](#1)\n",
    "    * [2.1. Load Libraries](#1.1)    \n",
    "    * [2.2. Load Dataset](#1.2)\n",
    "* [3. Data Preparation and Feature Selection](#2)\n",
    "    * [3.1. Preparing the predicted variable](#2.1)    \n",
    "    * [3.2. Feature Selection-Limit the Feature Space](#2.2)\n",
    "* [4.Evaluate Algorithms and Models](#4)        \n",
    "    * [4.1. Train/Test Split](#4.1)\n",
    "    * [4.2. Test Options and Evaluation Metrics](#4.2)\n",
    "    * [4.3. Compare Models and Algorithms](#4.3)\n",
    "* [5. Model Tuning and Grid Search](#5)  \n",
    "* [6. Finalize the Model](#6)  \n",
    "    * [6.1. Results on test dataset](#6.1)\n",
    "    * [6.2. Feature Importance](#6.1)\n",
    "    * [6.2. Feature Intuition](#6.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"This initiative focuses on developing an advanced machine learning system geared towards portfolio management optimization. The primary goal is to design an algorithm that can effectively diagnose investor risk profiles, construct efficient investment frontiers, and provide data-driven recommendations for maximizing portfolio returns. This sophisticated system caters to a spectrum of users, including both newcomers and seasoned investors, delivering insights that have the potential to reshape portfolio management strategies through data analytics and predictive modeling techniques.\n",
    "\n",
    "## Phase 2 ##\n",
    "This notebook marks the second phase of our project, where we delve into training a specialized machine learning model to forecast risk tolerance. Leveraging an array of pertinent features, the algorithm is designed to predict an investor's risk appetite based on their individual characteristics. This predictive prowess can substantially enhance our ability to tailor investment strategies, thus deepening the data-driven aspects of portfolio management.\"\n",
    "\n",
    "#Disclamer#\n",
    "\n",
    "\"This project is built upon the foundation laid by Hariom Tatsat in his book 'Machine Learning and Data Science Blueprints for Finance.' Specifically, it draws inspiration from Chapter 5's exploration of Supervised Learning, Regression, and Time Series models. The project closely follows Case Study 3, which delves into the critical area of Investor Risk Tolerance and Robo-advisors. The objective is to extend and build upon Tatsat's insights, methodologies, and findings to create an innovative machine learning application that optimizes investment portfolio management.\"\n",
    "\n",
    "For this case study the data used is from survey of Consumer Finances which is conducted by the Federal Reserve\n",
    "Board. The data source is : \n",
    "https://www.federalreserve.gov/econres/scfindex.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# 2. Getting Started- Loading the data and python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Loading the python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d8fee34-f454-2642-8b06-ed719f0317e1"
   },
   "outputs": [],
   "source": [
    "from RTfuncs import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import copy \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Libraries for Deep Learning Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import LSTM\n",
    "#from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Libraries for Saving the Model\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "787e35f7-bf9e-0969-8d13-a54fa87f3519",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '../raw_data/clean_dataset.csv'\n",
    "dataset = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 3. Data Preparation and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## 3.1. Preparing the predicted variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Risk Tolerance 2019\n",
    "RT= calculate_risk_tolerance(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_copy(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Null Values =',dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset, null_values_exist = preprocess_dataset(dataset)\n",
    "print('Null Values Exist:', null_values_exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the risk tolerance of 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(preprocessed_dataset['RT'], hist=True, kde=False, \n",
    "             bins=int(180/5), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the behavior of the individuals reversed in 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "## 3.2. Feature Selection-Limit the Feature Space "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2.2'></a>\n",
    "### 3.2.2.  Features elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list2 = ['HHSEX',\n",
    "              'AGE',\n",
    "              'EDCL',\n",
    "              'MARRIED',\n",
    "              'KIDS',\n",
    "              'FAMSTRUCT',\n",
    "              'OCCAT1',\n",
    "              'INCOME',\n",
    "              'WSAVED',\n",
    "              'YESFINRISK',\n",
    "              'NETWORTH',\n",
    "              'RT'\n",
    "              ]\n",
    "dataset = preprocess_and_drop_columns(preprocessed_dataset, keep_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the correlation among the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = dataset.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_matrix(dataset, figsize=(15, 15)):\n",
    "    scatter_matrix(dataset, figsize=figsize)\n",
    "    plt.show()\n",
    "    \n",
    "plot_scatter_matrix(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# 4. Evaluate Algorithms and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us evaluate the algorithms and the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "## 4.1. Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a train and test split in this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = prepare_train_validation_sets(dataset, 'RT', test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "## 4.2. Test Options and Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5702bc31-06bf-8b6a-42de-366a6b3311a8"
   },
   "outputs": [],
   "source": [
    "# test options for regression\n",
    "num_folds = 10\n",
    "scoring = 'neg_mean_squared_error'\n",
    "scoring ='neg_mean_absolute_error'\n",
    "scoring = 'r2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "## 4.3. Compare Models and Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "772802f7-f4e4-84ee-6377-6464ab2e5da4"
   },
   "outputs": [],
   "source": [
    "regression_models = create_regression_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a784ab4a-eb59-98cc-76cf-b55f382d057a"
   },
   "outputs": [],
   "source": [
    "model_names, model_results, best_model = perform_cross_validation_and_store_results_with_best_model(regression_models, X_train, Y_train, num_folds=10, seed=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(model_results)\n",
    "ax.set_xticklabels(model_names)\n",
    "fig.set_size_inches(15,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non linear models perform better than the linear models, which means that a non linear relationship between the risk tolerance and the difference variables use to predict it. Given random forest regression is one of the best methods, we use it for further grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# 5. Model Tuning and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "848ca488-b0fd-8e93-2e68-23d32c71d89c"
   },
   "source": [
    "Given that the Random Forest is the best model, Grid Search is performed on Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_grid_search_random_forest(X_train, Y_train, best_model, num_folds=10, seed=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest with number of estimators 350, is the best model after grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# 6. Finalise the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize Model with best parameters found during tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.1'></a>\n",
    "## 6.1. Results on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= create_and_fit_model(X_train, Y_train, RandomForestRegressor, n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = model.predict(X_train)\n",
    "r2_train = calculate_r2_score(predictions_train, Y_train)\n",
    "print(\"R^2 Score (Train):\", r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9725666-3c21-69d1-ddf6-45e47d982444"
   },
   "outputs": [],
   "source": [
    "mse, r2 = evaluate_regression_model(model, X_validation, Y_validation)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the mean square error and R2 shown above for the test set, the results look good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.2'></a>\n",
    "## 6.2. Feature Importance and Features Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the details above Random forest be worthy of further study.\n",
    "Let us look into the Feature Importance of the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "model = RandomForestRegressor(n_estimators= 200,n_jobs=-1)\n",
    "model.fit(X_train,Y_train)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the chart above, income and networth followed by age and willingness to take risk are the key variables to decide the risk tolerance. These variables have been considered as the key variables to model the risk tolerance across several literature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.3'></a>\n",
    "## 6.3. Save Model for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'finalized_model.sav'\n",
    "save_model_to_pickle(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'finalized_model.sav'\n",
    "load_and_evaluate_model(model_filename, X_validation, Y_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__:\n",
    "\n",
    "We showed that machine learning models might be able to objectively\n",
    "analyze the behavior of different investors in a changing market and attribute these\n",
    "changes to variables involved in determining risk appetite. With an increase in the\n",
    "volume of investorâ€™s data and availability of rich machine learning infrastructure,\n",
    "such models might prove to be more useful.\n",
    "\n",
    "We saw that there is a non-linear relationship between the variables and the risk tolerance. Income and net worth followed by age and willingness to take risk are the key variables to decide the risk tolerance. These variables have been considered as the key variables to model the risk tolerance across several literature.\n"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 206,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
